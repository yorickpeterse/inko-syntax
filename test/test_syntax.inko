import std.test (Tests)
import syntax (
  Buffer, EOF, Keywords, Language, Languages, Lexer, Token, TokenKind,
)

type DummyLexer {
  let @buffer: Buffer

  fn static new(bytes: ref ByteArray) -> DummyLexer {
    DummyLexer(Buffer.new(bytes))
  }
}

impl Lexer for DummyLexer {
  fn pub mut next -> Option[Token] {
    Option.None
  }

  fn pub mut buffer -> mut Buffer {
    @buffer
  }
}

fn pub tests(t: mut Tests) {
  t.test('Buffer.size', fn (t) {
    let bytes = 'abc'.to_byte_array
    let buf = Buffer.new(bytes)

    t.equal(buf.size, 3)
  })

  t.test('Buffer.get', fn (t) {
    let bytes = 'abc'.to_byte_array
    let buf = Buffer.new(bytes)

    t.equal(buf.get, 97)

    buf.offset += 1
    t.equal(buf.get, 98)
  })

  t.test('Buffer.peek', fn (t) {
    let bytes = 'abc'.to_byte_array
    let buf = Buffer.new(bytes)

    t.equal(buf.peek(0), 97)
    t.equal(buf.get, 97)
    t.equal(buf.peek(1), 98)
    t.equal(buf.get, 97)
    t.equal(buf.peek(200), EOF)
  })

  t.test('Buffer.slice', fn (t) {
    let bytes = 'abc'.to_byte_array
    let buf = Buffer.new(bytes)

    t.equal(buf.slice(start: 0, size: 3), 'abc')
  })

  t.panic('Buffer.slice with an out of bounds range', fn {
    let bytes = 'abc'.to_byte_array
    let buf = Buffer.new(bytes)

    buf.slice(start: 0, size: 10)
  })

  t.test('Buffer.token', fn (t) {
    let bytes = 'abc'.to_byte_array
    let buf = Buffer.new(bytes)

    buf.offset += 3
    t.equal(
      buf.token(TokenKind.Text, start: 0),
      Token.new(TokenKind.Text, 'abc'),
    )
  })

  t.test('Languages.new', fn (t) {
    let langs = Languages.new

    t.true(langs.get('fish').some?)
    t.true(langs.get('inko').some?)
    t.true(langs.get('make').some?)
    t.true(langs.get('ruby').some?)
    t.true(langs.get('rust').some?)
    t.true(langs.get('shell').some?)
    t.true(langs.get('toml').some?)
    t.true(langs.get('json').some?)
  })

  t.test('Languages.add', fn (t) {
    let langs = Languages.empty

    langs.add(
      Language(
        name: 'foo',
        aliases: ['bar'],
        builder: fn (inp) { DummyLexer.new(inp) as Lexer },
      ),
    )

    langs.add(
      Language(
        name: 'ruby',
        aliases: [],
        builder: fn (inp) { DummyLexer.new(inp) as Lexer },
      ),
    )

    t.true(langs.map.contains?('foo'))
    t.true(langs.map.contains?('ruby'))
    t.true(langs.aliases.contains?('bar'))
    t.false(langs.aliases.contains?('ruby'))
  })

  t.test('Languages.get', fn (t) {
    let langs = Languages.empty

    langs.add(
      Language(
        name: 'foo',
        aliases: ['bar'],
        builder: fn (inp) { DummyLexer.new(inp) as Lexer },
      ),
    )

    t.true(langs.get('foo').some?)
    t.true(langs.get('bar').some?)
  })

  t.test('Keywords.contains_range?', fn (t) {
    let kw = Keywords.new(
      ['foo', 'foobar', 'foofoo', 'fn', 'BLA', 'module', 'module_foo'],
    )

    t.true(kw.contains_range?('foo'.to_byte_array, 0, 3))
    t.true(kw.contains_range?('foobar'.to_byte_array, 0, 6))
    t.true(kw.contains_range?('foofoo'.to_byte_array, 0, 6))
    t.true(kw.contains_range?('fn'.to_byte_array, 0, 2))
    t.true(kw.contains_range?('BLA'.to_byte_array, 0, 3))
    t.true(kw.contains_range?('module'.to_byte_array, 0, 6))
    t.true(kw.contains_range?('module_foo'.to_byte_array, 0, 10))

    t.false(kw.contains_range?('a'.to_byte_array, 0, 3))
    t.false(kw.contains_range?('ab'.to_byte_array, 0, 3))
    t.false(kw.contains_range?('foobaz'.to_byte_array, 0, 6))
    t.false(kw.contains_range?('foobarx'.to_byte_array, 0, 7))
    t.false(kw.contains_range?('fnx'.to_byte_array, 0, 3))
    t.false(kw.contains_range?(ByteArray.new, 0, 0))
    t.false(kw.contains_range?(ByteArray.from_array([0]), 0, 1))
    t.false(kw.contains_range?(ByteArray.from_array([255]), 0, 1))
  })

  t.test('Keywords.contains_range? with a keyword preceded by text', fn (t) {
    let kw = Keywords.new(['foo'])
    let buf = 'abc foo'.to_byte_array

    t.true(kw.contains_range?(buf, at: 4, size: 3))
  })
}
