import std.test.Tests
import syntax.(Buffer, Lexer, Lexers, Token, TokenKind, EOF)
import syntax.lexers.inko

fn pub tests(t: mut Tests) {
  t.test('Buffer.size') fn (t) {
    let bytes = 'abc'.to_byte_array
    let buf = Buffer.new(bytes)

    t.equal(buf.size, 3)
  }

  t.test('Buffer.get') fn (t) {
    let bytes = 'abc'.to_byte_array
    let buf = Buffer.new(bytes)

    t.equal(buf.get, 97)

    buf.offset += 1
    t.equal(buf.get, 98)
  }

  t.test('Buffer.peek') fn (t) {
    let bytes = 'abc'.to_byte_array
    let buf = Buffer.new(bytes)

    t.equal(buf.peek(0), 97)
    t.equal(buf.get, 97)
    t.equal(buf.peek(1), 98)
    t.equal(buf.get, 97)
    t.equal(buf.peek(200), EOF)
  }

  t.test('Buffer.slice') fn (t) {
    let bytes = 'abc'.to_byte_array
    let buf = Buffer.new(bytes)

    t.equal(buf.slice(start: 0, size: 3), 'abc')
    t.equal(buf.slice(start: 0, size: 10), 'abc')
  }

  t.test('Buffer.advance_until_eol') fn (t) {
    let bytes = "abc\n".to_byte_array
    let buf = Buffer.new(bytes)

    buf.advance_until_eol
    t.equal(buf.offset, 3)

    buf.advance_until_eol
    t.equal(buf.offset, 3)
  }

  t.test('Buffer.advance_whitespace') fn (t) {
    let bytes = "a b\tc\rd\ne".to_byte_array
    let buf = Buffer.new(bytes)

    buf.advance_whitespace
    t.equal(buf.offset, 0)
    buf.offset += 1
    buf.advance_whitespace
    t.equal(buf.offset, 2)

    buf.offset += 1
    buf.advance_whitespace
    t.equal(buf.offset, 4)

    buf.offset += 1
    buf.advance_whitespace
    t.equal(buf.offset, 6)

    buf.offset += 1
    buf.advance_whitespace
    t.equal(buf.offset, 8)
  }

  t.test('Buffer.token') fn (t) {
    let bytes = 'abc'.to_byte_array
    let buf = Buffer.new(bytes)

    buf.offset += 3
    t.equal(
      buf.token(TokenKind.Text, start: 0),
      Token.new(TokenKind.Text, start: 0, size: 3)
    )
  }

  t.test('Lexers.create') fn (t) {
    let lexers = Lexers.new
    let bytes = '# test'.to_byte_array
    let lexer = lexers.create('inko', bytes)

    t.true(lexer.some?)
    t.equal(lexer.unwrap.language_identifier, 'inko')
  }

  t.test('Lexers.add') fn (t) {
    let lexers = Lexers.new
    let bytes = '# test'.to_byte_array

    lexers.add('kittens') fn (in) { inko.Lexer.new(in) as Lexer }

    let lexer = lexers.create('kittens', bytes)

    t.true(lexer.some?)
    t.equal(lexer.unwrap.language_identifier, 'inko')
  }
}
