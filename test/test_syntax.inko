import std.iter.Iter
import std.test.Tests
import syntax.(Buffer, Lexer, Language, Languages, Token, TokenKind, EOF)

class DummyLexer {
  let @buffer: Buffer

  fn static new(bytes: ref ByteArray) -> DummyLexer {
    DummyLexer { @buffer = Buffer.new(bytes) }
  }
}

impl Iter[Token] for DummyLexer {
  fn pub mut next -> Option[Token] {
    Option.None
  }
}

impl Lexer for DummyLexer {
  fn pub mut buffer -> mut Buffer {
    @buffer
  }
}

fn pub tests(t: mut Tests) {
  t.test('Buffer.size') fn (t) {
    let bytes = 'abc'.to_byte_array
    let buf = Buffer.new(bytes)

    t.equal(buf.size, 3)
  }

  t.test('Buffer.get') fn (t) {
    let bytes = 'abc'.to_byte_array
    let buf = Buffer.new(bytes)

    t.equal(buf.get, 97)

    buf.offset += 1
    t.equal(buf.get, 98)
  }

  t.test('Buffer.peek') fn (t) {
    let bytes = 'abc'.to_byte_array
    let buf = Buffer.new(bytes)

    t.equal(buf.peek(0), 97)
    t.equal(buf.get, 97)
    t.equal(buf.peek(1), 98)
    t.equal(buf.get, 97)
    t.equal(buf.peek(200), EOF)
  }

  t.test('Buffer.slice') fn (t) {
    let bytes = 'abc'.to_byte_array
    let buf = Buffer.new(bytes)

    t.equal(buf.slice(start: 0, size: 3), 'abc')
    t.equal(buf.slice(start: 0, size: 10), 'abc')
  }

  t.test('Buffer.advance_until_eol') fn (t) {
    let bytes = "abc\n".to_byte_array
    let buf = Buffer.new(bytes)

    buf.advance_until_eol
    t.equal(buf.offset, 3)

    buf.advance_until_eol
    t.equal(buf.offset, 3)
  }

  t.test('Buffer.advance_whitespace') fn (t) {
    let bytes = "a b\tc\rd\ne".to_byte_array
    let buf = Buffer.new(bytes)

    buf.advance_whitespace
    t.equal(buf.offset, 0)
    buf.offset += 1
    buf.advance_whitespace
    t.equal(buf.offset, 2)

    buf.offset += 1
    buf.advance_whitespace
    t.equal(buf.offset, 4)

    buf.offset += 1
    buf.advance_whitespace
    t.equal(buf.offset, 6)

    buf.offset += 1
    buf.advance_whitespace
    t.equal(buf.offset, 8)
  }

  t.test('Buffer.token') fn (t) {
    let bytes = 'abc'.to_byte_array
    let buf = Buffer.new(bytes)

    buf.offset += 3
    t.equal(
      buf.token(TokenKind.Text, start: 0),
      Token.new(TokenKind.Text, start: 0, size: 3)
    )
  }

  t.test('Languages.add') fn (t) {
    let langs = Languages.empty

    langs.add(Language {
      @name = 'foo',
      @aliases = ['bar'],
      @extensions = ['foo', 'bar'],
      @builder = fn (in) { DummyLexer.new(in) as Lexer }
    })

    langs.add(Language {
      @name = 'ruby',
      @aliases = [],
      @extensions = ['rb'],
      @builder = fn (in) { DummyLexer.new(in) as Lexer }
    })

    t.true(langs.map.contains?('foo'))
    t.true(langs.map.contains?('ruby'))

    t.true(langs.aliases.contains?('bar'))
    t.false(langs.aliases.contains?('ruby'))

    t.true(langs.extensions.contains?('foo'))
    t.true(langs.extensions.contains?('bar'))
    t.true(langs.extensions.contains?('rb'))

    let foo = langs.map.get('foo')
    let ruby = langs.map.get('ruby')

    t.equal(langs.aliases.get('bar').name, foo.name)
    t.equal(langs.extensions.get('foo').name, foo.name)
    t.equal(langs.extensions.get('bar').name, foo.name)
    t.equal(langs.extensions.get('rb').name, ruby.name)
  }
}
