# Lexical analysis of Inko source code.
import std.iter.Iter
import std.set.Set
import syntax.(EOF, Buffer, Token, TokenKind)
import syntax.helpers.(digit?, letter?, multibyte?, symbol?, whitespace?)

let DQUOTE = 34
let HASH = 35
let SQUOTE = 39
let PLUS = 43
let HYPHEN = 45
let PERIOD = 46
let QUEST = 63
let AT = 64
let UPPER_E = 69
let BSLASH = 92
let UNDER = 95
let LOWER_E = 101

let KEYWORDS = [
  'as', 'and', 'async', 'break', 'builtin', 'case', 'class', 'else', 'enum',
  'extern', 'false', 'fn', 'for', 'if', 'impl', 'import', 'let', 'loop',
  'match', 'move', 'mut', 'next', 'nil', 'or', 'pub', 'recover', 'ref',
  'return', 'self', 'static', 'throw', 'trait', 'true', 'try', 'uni', 'while',
]

# A type that turns Inko source code into a stream of tokens.
class pub Lexer {
  let @buffer: Buffer
  let @keywords: Set[String]

  # Returns a new `Lexer` that lexes the given input.
  fn pub static new(bytes: ref ByteArray) -> Lexer {
    Lexer {
      @buffer = Buffer.new(bytes),
      @keywords = KEYWORDS.iter.reduce(Set.new) fn (set, kw) {
        set.insert(kw)
        set
      }
    }
  }

  fn mut single_string -> Token {
    string(TokenKind.SingleString, SQUOTE)
  }

  fn mut double_string -> Token {
    string(TokenKind.DoubleString, DQUOTE)
  }

  fn mut string(kind: TokenKind, quote: Int) -> Token {
    let start = @buffer.offset

    @buffer.offset += 1

    while @buffer.get != EOF and @buffer.get != quote {
      @buffer.offset +=
        if @buffer.get == BSLASH and @buffer.peek(1) == quote { 2 } else { 1 }
    }

    @buffer.offset += 1
    @buffer.token(kind, start)
  }

  fn mut symbol -> Token {
    @buffer.offset += 1
    @buffer.token(TokenKind.Text, @buffer.offset - 1)
  }

  fn mut word -> Token {
    let start = @buffer.offset

    advance_word

    let kind = match @buffer.slice(start, @buffer.offset) {
      case word if @keywords.contains?(word) -> TokenKind.Keyword
      case _ -> TokenKind.Text
    }

    @buffer.token(kind, start)
  }

  fn mut field -> Token {
    let start = @buffer.offset

    @buffer.offset += 1
    advance_word

    if @buffer.offset == (start + 1) {
      @buffer.token(TokenKind.Text, start)
    } else {
      @buffer.token(TokenKind.Field, start)
    }
  }

  fn mut multibyte_word -> Token {
    let start = @buffer.offset

    while multibyte?(@buffer.get) { @buffer.offset += 1 }

    @buffer.token(TokenKind.Text, start)
  }

  fn mut whitespace -> Token {
    let start = @buffer.offset

    @buffer.advance_whitespace
    @buffer.token(TokenKind.Text, start)
  }

  fn mut line_comment -> Token {
    let start = @buffer.offset

    @buffer.advance_until_eol
    @buffer.token(TokenKind.Comment, start)
  }

  fn mut number -> Token {
    let start = @buffer.offset

    digits

    match @buffer.get {
      case PERIOD -> {
        if digit?(@buffer.peek(1)).false? {
          return Token.new(TokenKind.Int, start, @buffer.offset - 1 - start)
        }

        @buffer.offset += 2
        digits
        @buffer.token(TokenKind.Float, start)
      }
      case LOWER_E or UPPER_E -> {
        match @buffer.peek(1) {
          case PLUS or HYPHEN if digit?(@buffer.peek(2)) -> @buffer.offset += 3
          case byte if digit?(byte) -> @buffer.offset += 2
          case _ -> return @buffer.token(TokenKind.Int, start)
        }

        digits
        @buffer.token(TokenKind.Float, start)
      }
      case _ -> @buffer.token(TokenKind.Int, start)
    }
  }

  fn mut single_byte -> Token {
    @buffer.offset += 1
    @buffer.token(TokenKind.Text, @buffer.offset - 1)
  }

  fn mut digits {
    while digit?(@buffer.get) or @buffer.get == UNDER { @buffer.offset += 1 }
  }

  fn mut advance_word {
    while @buffer.offset < @buffer.size {
      let cur = @buffer.get

      if letter?(cur) or digit?(cur) or cur == UNDER {
        @buffer.offset += 1
      } else if cur == QUEST {
        @buffer.offset += 1
        break
      } else {
        break
      }
    }
  }
}

impl Iter[Token] for Lexer {
  fn pub mut next -> Option[Token] {
    match @buffer.get {
      case DQUOTE -> Option.Some(double_string)
      case SQUOTE -> Option.Some(single_string)
      case HASH -> Option.Some(line_comment)
      case AT -> Option.Some(field)
      case byte if digit?(byte) -> Option.Some(number)
      case byte if symbol?(byte) -> Option.Some(symbol)
      case byte if letter?(byte) -> Option.Some(word)
      case byte if whitespace?(byte) -> Option.Some(whitespace)
      case byte if multibyte?(byte) -> Option.Some(multibyte_word)
      case EOF -> Option.None
      case _ -> Option.Some(single_byte)
    }
  }
}
