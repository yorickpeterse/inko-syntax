# Lexical analysis of TOML syntax.
import std.iter.Iter
import syntax.(
  EOF, Buffer, Keywords, Language, Lexer as LexerTrait, Languages, Token,
  TokenKind
)
import syntax.bytes
import syntax.helpers

let KEYWORDS = ['false', 'true']

# Registers the lexer with the lexers registry.
fn pub register(languages: mut Languages) {
  languages.add(Language {
    @name = 'toml',
    @aliases = [],
    @builder = fn (in) { Lexer.new(in) as LexerTrait }
  })
}

# A lexer for TOML.
class pub Lexer {
  let @buffer: Buffer
  let @keywords: Keywords

  # Returns a new `Lexer` that lexes the given input.
  fn pub static new(bytes: ref ByteArray) -> Lexer {
    Lexer {
      @buffer = Buffer.new(bytes),
      @keywords = Keywords.new(KEYWORDS),
    }
  }

  fn mut word -> Token {
    helpers.text_or_keyword(@buffer, @keywords) fn (b) {
      bytes.letter_or_digit?(b)
        or b == bytes.UNDER
        or (b == bytes.HYPHEN and bytes.letter_or_digit?(@buffer.peek(1)))
    }
  }
}

impl Iter[Token] for Lexer {
  fn pub mut next -> Option[Token] {
    match @buffer.get {
      case bytes.DQUOTE -> Option.Some(helpers.double_string(@buffer))
      case bytes.SQUOTE -> Option.Some(helpers.single_string(@buffer))
      case bytes.HASH -> Option.Some(helpers.line_comment(@buffer))
      case byte if bytes.digit?(byte) -> Option.Some(helpers.integer(@buffer))
      case byte if bytes.letter?(byte) -> Option.Some(word)
      case byte if bytes.whitespace?(byte) -> {
        Option.Some(helpers.whitespace(@buffer))
      }
      case byte if bytes.multibyte?(byte) -> {
        Option.Some(helpers.multi_byte(@buffer))
      }
      case EOF -> Option.None
      case _ -> Option.Some(helpers.single_byte(@buffer))
    }
  }
}

impl LexerTrait for Lexer {
  fn pub mut buffer -> mut Buffer {
    @buffer
  }
}
