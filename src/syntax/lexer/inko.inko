# Lexical analysis of Inko syntax.
import std.iter.Iter
import syntax.(
  EOF, Buffer, Keywords, Language, Lexer as LexerTrait, Languages, Token,
  TokenKind
)
import syntax.bytes
import syntax.helpers

let KEYWORDS = [
  'and', 'as', 'async', 'break', 'builtin', 'case', 'class', 'else', 'enum',
  'extern', 'false', 'fn', 'for', 'if', 'impl', 'import', 'let', 'loop',
  'match', 'move', 'mut', 'next', 'nil', 'or', 'pub', 'recover', 'ref',
  'return', 'self', 'static', 'throw', 'trait', 'true', 'try', 'uni', 'while',
]

# Registers the lexer with the lexers registry.
fn pub register(languages: mut Languages) {
  languages.add(Language {
    @name = 'inko',
    @aliases = [],
    @builder = fn (in) { Lexer.new(in) as LexerTrait }
  })
}

fn word_byte?(buffer: mut Buffer, byte: Int) -> Bool {
  if bytes.letter_or_digit?(byte) or byte == bytes.UNDER  { return true }
  if byte == bytes.QUEST { buffer.offset += 1 }
  false
}

# A lexer for Inko syntax.
class pub Lexer {
  let @buffer: Buffer
  let @keywords: Keywords

  # Returns a new `Lexer` that lexes the given input.
  fn pub static new(bytes: ref ByteArray) -> Lexer {
    Lexer {
      @buffer = Buffer.new(bytes),
      @keywords = Keywords.new(KEYWORDS),
    }
  }

  fn mut word -> Token {
    helpers
      .text_or_keyword(@buffer, @keywords) fn (b) { word_byte?(@buffer, b) }
  }

  fn mut field -> Token {
    let start = @buffer.offset

    @buffer.offset += 1
    @buffer.advance_while fn (b) { word_byte?(@buffer, b) }

    if @buffer.offset == (start + 1) {
      @buffer.token(TokenKind.Text, start)
    } else {
      @buffer.token(TokenKind.Field, start)
    }
  }

  fn mut number -> Token {
    let start = @buffer.offset

    digits

    match @buffer.get {
      case bytes.PERIOD -> {
        if bytes.digit?(@buffer.peek(1)).false? {
          return Token.new(TokenKind.Int, start, @buffer.offset - 1 - start)
        }

        @buffer.offset += 2
        digits
        @buffer.token(TokenKind.Float, start)
      }
      case bytes.LOWER_E or bytes.UPPER_E -> {
        match @buffer.peek(1) {
          case bytes.PLUS or bytes.HYPHEN if bytes.digit?(@buffer.peek(2)) -> {
            @buffer.offset += 3
          }
          case byte if bytes.digit?(byte) -> @buffer.offset += 2
          case _ -> return @buffer.token(TokenKind.Int, start)
        }

        digits
        @buffer.token(TokenKind.Float, start)
      }
      case _ -> @buffer.token(TokenKind.Int, start)
    }
  }

  fn mut digits {
    @buffer.advance_while fn (b) { bytes.digit?(b) or b == bytes.UNDER }
  }
}

impl Iter[Token] for Lexer {
  fn pub mut next -> Option[Token] {
    match @buffer.get {
      case bytes.DQUOTE -> Option.Some(helpers.double_string(@buffer))
      case bytes.SQUOTE -> Option.Some(helpers.single_string(@buffer))
      case bytes.HASH -> Option.Some(helpers.line_comment(@buffer))
      case bytes.AT -> Option.Some(field)
      case byte if bytes.digit?(byte) -> Option.Some(number)
      case byte if bytes.letter?(byte) -> Option.Some(word)
      case byte if bytes.whitespace?(byte) -> {
        Option.Some(helpers.whitespace(@buffer))
      }
      case byte if bytes.multibyte?(byte) -> {
        Option.Some(helpers.multi_byte(@buffer))
      }
      case EOF -> Option.None
      case _ -> Option.Some(helpers.single_byte(@buffer))
    }
  }
}

impl LexerTrait for Lexer {
  fn pub mut buffer -> mut Buffer {
    @buffer
  }
}
