# Lexical analysis of Bash/shell syntax.
import std.iter.Iter
import syntax.(
  EOF, Buffer, Keywords, Language, Lexer as LexerTrait, Languages, Token,
  TokenKind
)
import syntax.helpers.(digit?, letter?, multibyte?, whitespace?)

let DQUOTE = 34
let HASH = 35
let SQUOTE = 39
let PLUS = 43
let HYPHEN = 45
let PERIOD = 46
let QUEST = 63
let AT = 64
let UPPER_E = 69
let BSLASH = 92
let UNDER = 95
let LOWER_E = 101

let KEYWORDS = [
  'alias', 'bg', 'bind', 'break', 'builtin', 'caller', 'cd', 'command',
  'compgen', 'complete', 'continue', 'declare', 'dirs', 'disown', 'do', 'done',
  'elif', 'else', 'enable', 'esac', 'eval', 'exec', 'exit', 'export', 'false',
  'fc', 'fg', 'fi', 'for', 'function', 'getopts', 'hash', 'help', 'history',
  'if', 'in', 'jobs', 'let', 'local', 'logout', 'mapfile', 'popd', 'pushd',
  'pwd', 'read', 'readonly', 'return', 'select', 'set', 'shift', 'shopt',
  'source', 'suspend', 'test', 'then', 'time', 'times', 'trap', 'true', 'type',
  'typeset', 'ulimit', 'umask', 'unalias', 'unset', 'until', 'wait', 'while',
]

# Registers the lexer with the lexers registry.
fn pub register(languages: mut Languages) {
  languages.add(Language {
    @name = 'shell',
    @aliases = ['bash', 'sh', 'zsh', 'ksh', 'shell'],
    @builder = fn (in) { Lexer.new(in) as LexerTrait }
  })
}

# A lexer for common shell syntax, such as Bash and Zsh.
class pub Lexer {
  let @buffer: Buffer
  let @keywords: Keywords

  # Returns a new `Lexer` that lexes the given input.
  fn pub static new(bytes: ref ByteArray) -> Lexer {
    Lexer {
      @buffer = Buffer.new(bytes),
      @keywords = Keywords.new(KEYWORDS),
    }
  }

  fn mut single_string -> Token {
    string(TokenKind.SingleString, SQUOTE)
  }

  fn mut double_string -> Token {
    string(TokenKind.DoubleString, DQUOTE)
  }

  fn mut string(kind: TokenKind, quote: Int) -> Token {
    let start = @buffer.offset

    @buffer.offset += 1
    @buffer.advance_while fn (b) {
      if b == quote { return false }
      if b == BSLASH and @buffer.peek(1) == quote { @buffer.offset += 2 }
      true
    }

    @buffer.offset += 1
    @buffer.token(kind, start)
  }

  fn mut word -> Token {
    let start = @buffer.offset

    @buffer.advance_while fn (b) { letter?(b) or digit?(b) or b == UNDER }

    let size = @buffer.offset - start
    let kind = if @keywords.contains_range?(@buffer.bytes, start, size) {
      TokenKind.Keyword
    } else {
      TokenKind.Text
    }

    @buffer.token(kind, start)
  }

  fn mut line_comment -> Token {
    let start = @buffer.offset

    @buffer.advance_until_eol
    @buffer.token(TokenKind.Comment, start)
  }

  fn mut number -> Token {
    let start = @buffer.offset

    @buffer.advance_while fn (b) { digit?(b) }
    @buffer.token(TokenKind.Int, start)
  }

  fn mut whitespace -> Token {
    let start = @buffer.offset

    @buffer.advance_whitespace
    @buffer.token(TokenKind.Text, start)
  }

  fn mut single_byte -> Token {
    @buffer.offset += 1
    @buffer.token(TokenKind.Text, @buffer.offset - 1)
  }

  fn mut multibyte_word -> Token {
    let start = @buffer.offset

    @buffer.advance_while fn (b) { multibyte?(b) }
    @buffer.token(TokenKind.Text, start)
  }
}

impl Iter[Token] for Lexer {
  fn pub mut next -> Option[Token] {
    match @buffer.get {
      case DQUOTE -> Option.Some(double_string)
      case SQUOTE -> Option.Some(single_string)
      case HASH -> Option.Some(line_comment)
      case byte if digit?(byte) -> Option.Some(number)
      case byte if letter?(byte) -> Option.Some(word)
      case byte if whitespace?(byte) -> Option.Some(whitespace)
      case byte if multibyte?(byte) -> Option.Some(multibyte_word)
      case EOF -> Option.None
      case _ -> Option.Some(single_byte)
    }
  }
}

impl LexerTrait for Lexer {
  fn pub mut buffer -> mut Buffer {
    @buffer
  }
}
