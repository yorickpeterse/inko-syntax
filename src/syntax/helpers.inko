# Methods for turning bytes into tokens.
import syntax.(Buffer, Keywords, Token, TokenKind)
import syntax.bytes

fn token_containing(
  buffer: mut Buffer,
  kind: TokenKind,
  condition: fn (Int) -> Bool,
) -> Token {
  let start = buffer.offset

  buffer.advance_while(condition)
  buffer.token(kind, start)
}

fn delimited_token(
  buffer: mut Buffer,
  kind: TokenKind,
  close: Int,
  escape: Bool,
) -> Token {
  let start = buffer.offset

  # Advance over the opening byte.
  buffer.offset += 1
  buffer.advance_while fn (b) {
    if b == close {
      buffer.offset += 1
      return false
    }

    if escape and b == bytes.BSLASH and buffer.peek(1) == close {
      buffer.offset += 2
    }

    true
  }

  buffer.token(kind, start)
}

fn single_byte(buffer: mut Buffer) -> Token {
  let start = buffer.offset

  buffer.offset += 1
  buffer.token(TokenKind.Text, start)
}

fn multi_byte(buffer: mut Buffer) -> Token {
  token_containing(buffer, TokenKind.Text) fn (b) { bytes.multibyte?(b) }
}

fn whitespace(buffer: mut Buffer) -> Token {
  token_containing(buffer, TokenKind.Text) fn (b) { bytes.whitespace?(b) }
}

fn integer(buffer: mut Buffer) -> Token {
  token_containing(buffer, TokenKind.Int) fn (b) { bytes.digit?(b) }
}

fn line_comment(buffer: mut Buffer) -> Token {
  token_containing(buffer, TokenKind.Comment) fn (b) { b != bytes.LF }
}

fn single_string(buffer: mut Buffer) -> Token {
  delimited_token(buffer, TokenKind.SingleString, bytes.SQUOTE, escape: true)
}

fn double_string(buffer: mut Buffer) -> Token {
  delimited_token(buffer, TokenKind.DoubleString, bytes.DQUOTE, escape: true)
}

fn text_or_keyword(
  buffer: mut Buffer,
  keywords: ref Keywords,
  condition: fn (Int) -> Bool,
) -> Token {
  let start = buffer.offset

  buffer.advance_while(condition)

  if keywords.contains_range?(buffer.bytes, start, buffer.offset - start) {
    buffer.token(TokenKind.Keyword, start)
  } else {
    buffer.token(TokenKind.Text, start)
  }
}
