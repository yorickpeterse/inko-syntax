# Formatting of token streams as HTML.
import builder.html.Document
import std.iter.Iter
import std.string.StringBuffer
import syntax.(Token, TokenKind)

# A type that forms a lexer's token stream as HTML.
#
# The generated HTML is compatible with [Pygments](https://pygments.org/)
# stylesheets.
class pub Html {
  # The class to apply to the surrounding div and the <pre> element.
  let pub @class: String

  # Returns a new HTML formatter.
  fn pub static new -> Html {
    Html { @class = 'highlight' }
  }

  # Formats a token stream as HTML.
  #
  # The `language` argument is the name of the language that's highlighted, and
  # is added as a class to the `pre` element.
  #
  # The `source` argument is the input buffer that is tokenized.
  #
  # The `tokens` argument is an iterator over the tokens produced from the
  # `source` buffer.
  fn pub format[I: mut + Iter[Token]](
    language: String,
    source: ref ByteArray,
    tokens: I,
  ) -> String {
    let doc = Document.new
    let code = doc
      .div
      .attr('class', @class)
      .pre
      .attr('class', "{@class} {language}")
      .code

    tokens.each fn (tok) {
      # These classes are taken from
      # https://github.com/pygments/pygments/blob/8f3bec7982ba52915ee95f34f18e188243364600/pygments/token.py.
      let cls = match tok.kind {
        case Comment -> 'c'
        case DoubleString -> 's2'
        case SingleString -> 's1'
        case Int -> 'mi'
        case Float -> 'mf'
        case Keyword -> 'k'
        case Field -> 'vi'
        case Text -> ''
      }

      let el = if cls.size > 0 { code.span.attr('class', cls) } else { code }

      el.text(source.slice(tok.start, tok.size).into_string)
    }

    doc.fragment = true
    doc.to_string
  }
}
