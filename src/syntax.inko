# A simple syntax highlighting library for Inko.
import std.cmp.Equal
import std.fmt.(Format as Format, Formatter)
import std.hash.(Hash, Hasher)
import std.iter.Iter
import syntax.format
import syntax.helpers.(LF, whitespace?)
import syntax.lexers.inko

# The value returned by `Lexer.current` and `Lexer.peek` to signal the end of
# the input is reached.
let pub EOF = -1

class pub enum TokenKind {
  # A single or multi-line comment.
  case Comment

  # A double quoted string.
  case DoubleString

  # A single quoted string.
  case SingleString

  # An integer.
  case Int

  # A float (e.g. `10.5` or `10e5`).
  case Float

  # Regular text, such as unrecognized/highlighted words or whitespace.
  case Text

  # A keyword, such as `class`.
  case Keyword

  # A reference to a field, such as `self.foo` in Rust or `@foo` in Inko.
  case Field
}

impl Hash for TokenKind {
  fn pub hash[H: mut + Hasher](hasher: mut H) {
    let val = match self {
      case Comment -> 0
      case DoubleString -> 1
      case SingleString -> 2
      case Int -> 3
      case Float -> 4
      case Text -> 5
      case Keyword -> 6
      case Field -> 7
    }

    hasher.write(val)
  }
}

impl Equal[TokenKind] for TokenKind {
  fn pub ==(other: ref TokenKind) -> Bool {
    match (self, other) {
      case (Comment, Comment) -> true
      case (DoubleString, DoubleString) -> true
      case (SingleString, SingleString) -> true
      case (Int, Int) -> true
      case (Float, Float) -> true
      case (Text, Text) -> true
      case (Keyword, Keyword) -> true
      case (Field, Field) -> true
      case _ -> false
    }
  }
}

impl Format for TokenKind {
  fn pub fmt(formatter: mut Formatter) {
    match self {
      case Comment -> formatter.tuple('Comment').finish
      case DoubleString -> formatter.tuple('DoubleString').finish
      case SingleString -> formatter.tuple('SingleString').finish
      case Int -> formatter.tuple('Int').finish
      case Float -> formatter.tuple('Float').finish
      case Text -> formatter.tuple('Text').finish
      case Keyword -> formatter.tuple('Keyword').finish
      case Field -> formatter.tuple('Field').finish
    }
  }
}

# A token to highlight.
class pub Token {
  # The kind/type of token.
  let pub @kind: TokenKind

  # The byte offset the value of the token starts at.
  let pub @start: Int

  # The number of bytes the value of this token contains.
  let pub @size: Int

  # Returns a new `Token`.
  fn pub static new(kind: TokenKind, start: Int, size: Int) -> Token {
    Token { @kind = kind, @start = start, @size = size }
  }
}

impl Equal[Token] for Token {
  fn pub ==(other: ref Token) -> Bool {
    @kind == other.kind and @start == other.start and @size == other.size
  }
}

impl Format for Token {
  fn pub fmt(formatter: mut Formatter) {
    formatter
      .object('Token')
      .field('kind', @kind)
      .field('start', @start)
      .field('size', @size)
      .finish
  }
}

# A type that turns a buffer into a token stream.
trait pub Lexer: Iter[Token] {
  # The buffer to turn into a token stream.
  fn pub mut buffer -> mut Buffer

  # Returns an identifier describing the name of the language this lexer
  # processes.
  #
  # The name shouldn't contain any spaces, and be suitable for use in e.g. the
  # "class" attribute of an HTML element.
  fn pub language_identifier -> String
}

# A type that represents a bunch of bytes to process using a lexer.
class pub Buffer {
  # The bytes that are to be turned into a token stream.
  let pub @bytes: ref ByteArray

  # The current byte offset.
  let pub @offset: Int

  # Returns a new `Buffer` that wraps the given `ByteArray`.
  fn pub static new(bytes: ref ByteArray) -> Buffer {
    Buffer { @bytes = bytes, @offset = 0 }
  }

  # Returns the total number of bytes in the buffer.
  fn pub size -> Int {
    @bytes.size
  }

  # Returns the byte at the current byte offset.
  fn pub get -> Int {
    peek(0)
  }

  # Returns the byte that is at `amount` bytes relative to the current offset.
  #
  # If the offset is out of range, the `EOF` byte is returned.
  fn pub peek(amount: Int) -> Int {
    let idx = @offset + amount

    if idx < @bytes.size { @bytes.byte(idx) } else { EOF }
  }

  # Slices the buffer into a substring.
  fn pub slice(start: Int, size: Int) -> String {
    @bytes.slice(start, size).into_string
  }

  # Advances the cursor until reaching the end of the current line.
  fn pub mut advance_until_eol {
    while get != EOF and get != LF { @offset += 1 }
  }

  # Advances the cursor until reaching the first non-whitespace byte.
  fn pub mut advance_whitespace {
    while whitespace?(get) { @offset += 1 }
  }

  # Returns a new token starting at the given offset that ranges until the
  # current offset.
  fn pub token(kind: TokenKind, start: Int) -> Token {
    Token.new(kind, start, size: @offset - start)
  }
}

# A type used for syntax highlighting a stream of bytes.
#
# # Examples
#
# A basic example that uses the default settings:
#
#     import syntax.Syntax
#
#     Syntax.new('inko').unwrap.highlight('# This is a test'.to_byte_array)
#
# Using custom settings for the formatter:
#
#     import syntax.Syntax
#     import syntax.format.(Format, Html)
#
#     let syntax = Syntax.new('inko').unwrap
#     let format = Html.new
#
#     format.class = 'syntax-highlight'
#     syntax.format = format as Format
#     syntax.highlight('# This is a test'.to_byte_array)
class pub Syntax {
  # A closure that produces a lexer for the given bytes.
  #
  # The lexer is based on the language used to construct this `Syntax` for.
  let @lexer: fn (ref ByteArray) -> Lexer

  # The format to turn the token stream into.
  #
  # This field defaults to `syntax.format.Html`.
  let pub @format: format.Format

  # Returns a new syntax highlighter for the given language.
  #
  # If the language isn't recognized, a `None` is returned.
  fn pub static new(language: String) -> Option[Syntax] {
    let lexer = match language {
      case 'inko' -> fn (in) { inko.Lexer.new(in) as Lexer }
      case _ -> return Option.None
    }

    Option.Some(Syntax {
      @lexer = lexer,
      @format = format.Html.new as format.Format,
    })
  }

  # Syntax highlights the given bytes into a `String`.
  fn pub mut highlight(bytes: ref ByteArray) -> String {
    @format.format(@lexer.call(bytes))
  }
}
